apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: {{ kernel_resource_name }}
spec:
  restartPolicy:
    type: Never
  type: Python
  pythonVersion: "3"
  sparkVersion: 3.5.1
  image: {{ kernel_image }}
  mainApplicationFile: "local:///opt/spark/work-dir/python/scripts/launch_ipykernel.py"
  volumes:
    - name: nfsshare
      nfs:
        server: "nfs-service.storage.svc.cluster.local"
        path: "/shared"
        readOnly: false
  arguments:
    - "--kernel-id"
    - "{{ kernel_id }}"
    - "--spark-context-initialization-mode"
    - "{{ spark_context_initialization_mode }}"
    - "--response-address"
    - "{{ eg_response_address }}"
    - "--port-range"
    - "{{ eg_port_range }}"
    - "--public-key"
    - "{{ eg_public_key }}"
  driver:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
    env:
# Add any custom envs here that aren't already configured for the kernel's environment
# Note: For envs to flow to the pods, the webhook server must be enabled during deployment
# e.g., helm install my-release spark-operator/spark-operator --namespace spark-operator --set webhook.enable=true
#    - name: MY_DRIVER_ENV
#      value: "my_driver_value" "{{ kernel_service_account_name }}"
    serviceAccount: "{{ kernel_service_account_name }}"
    labels:
      kernel_id: "{{ kernel_id }}"
      app: enterprise-gateway
      component: kernel
    volumeMounts:
      - name: "nfsshare"
        mountPath: "/mnt/python/"
        subPath: "gdrive/Spark/python"
      - name: "nfsshare"
        mountPath: "/mnt/jars"
        subPath: "gdrive/Spark/jars"
      - name: "nfsshare"
        mountPath: "/opt/spark/work-dir/python/scripts/"
        subPath: "git/git-sync/spark/python/scripts/"
    lifecycle:
      postStart:
        exec:
          command: ["/bin/sh", "-c", "ln -s /mnt/jars/*.jar /opt/spark/jars/"]
    cores: 1
    #coreLimit: 1000m
    memory: 1024m
  executor:
    env:
# Add any custom envs here that aren't already configured for the kernel's environment
# Note: For envs to flow to the pods, the webhook server must be enabled during deployment
# e.g., helm install my-release spark-operator/spark-operator --namespace spark-operator --set webhook.enable=true
#    - name: MY_EXECUTOR_ENV
#      value: "my_executor_value"
    labels:
      kernel_id: "{{ kernel_id }}"
      app: enterprise-gateway
      component: worker
    image: {{ kernel_executor_image }}
    volumeMounts:
      - name: "nfsshare"
        mountPath: "/mnt/python/"
        subPath: "gdrive/Spark/python"
      - name: "nfsshare"
        mountPath: "/mnt/jars"
        subPath: "gdrive/Spark/jars"
      - name: "nfsshare"
        mountPath: "/opt/spark/work-dir/python/scripts/"
        subPath: "git/git-sync/spark/python/scripts/"
    lifecycle:
      postStart:
        exec:
          command: ["/bin/sh", "-c", "ln -s /mnt/jars/*.jar /opt/spark/jars/"]
    instances: 2
    cores: 1
    #coreLimit: 1000m
    memory: 1024m
    gpu:
      name: "nvidia.com/gpu-2gb"
      quantity: 1
{% if kernel_sparkapp_config_map %}
  sparkConfigMap: {{ kernel_sparkapp_config_map }}
{% endif %}
